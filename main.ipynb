{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceafaf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='image_folder',\n",
      "    full_name='image_folder/1.0.0',\n",
      "    description=\"\"\"\n",
      "    Generic image classification dataset.\n",
      "    \"\"\",\n",
      "    homepage='https://www.tensorflow.org/datasets/catalog/image_folder',\n",
      "    data_dir='Dataset/Grayscale/Vehicles_Detection.v9i.tensorflow/image_folder/1.0.0',\n",
      "    file_format=tfrecord,\n",
      "    download_size=Unknown size,\n",
      "    dataset_size=Unknown size,\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(None, None, 3), dtype=uint8),\n",
      "        'image/filename': Text(shape=(), dtype=string),\n",
      "        'label': ClassLabel(shape=(), dtype=int64, num_classes=0),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    nondeterministic_order=False,\n",
      "    splits={\n",
      "    },\n",
      "    citation=\"\"\"\"\"\",\n",
      ")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unrecognized split train. Subsplit API not yet supported for ImageFolder. Split name should be one of [].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m builder \u001b[38;5;241m=\u001b[39m tfds\u001b[38;5;241m.\u001b[39mfolder_dataset\u001b[38;5;241m.\u001b[39mImageFolder(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset/Grayscale/Vehicles_Detection.v9i.tensorflow/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(builder\u001b[38;5;241m.\u001b[39minfo)\n\u001b[0;32m----> 4\u001b[0m raw_train \u001b[38;5;241m=\u001b[39m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m raw_test \u001b[38;5;241m=\u001b[39m builder\u001b[38;5;241m.\u001b[39mas_dataset(split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, shuffle_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m raw_valid \u001b[38;5;241m=\u001b[39m builder\u001b[38;5;241m.\u001b[39mas_dataset(split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m, shuffle_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf312/lib/python3.12/site-packages/tensorflow_datasets/core/logging/__init__.py:176\u001b[0m, in \u001b[0;36m_FunctionDecorator.__call__\u001b[0;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_call()\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m   metadata\u001b[38;5;241m.\u001b[39mmark_error()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf312/lib/python3.12/site-packages/tensorflow_datasets/core/dataset_builder.py:1046\u001b[0m, in \u001b[0;36mDatasetBuilder.as_dataset\u001b[0;34m(self, split, batch_size, shuffle_files, decoders, read_config, as_supervised)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;66;03m# Create a dataset for each of the given splits\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m build_single_dataset \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_single_dataset,\n\u001b[1;32m   1040\u001b[0m     shuffle_files\u001b[38;5;241m=\u001b[39mshuffle_files,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1044\u001b[0m     as_supervised\u001b[38;5;241m=\u001b[39mas_supervised,\n\u001b[1;32m   1045\u001b[0m )\n\u001b[0;32m-> 1046\u001b[0m all_ds \u001b[38;5;241m=\u001b[39m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuild_single_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m all_ds\n",
      "File \u001b[0;32m~/miniconda3/envs/tf312/lib/python3.12/site-packages/tree/__init__.py:428\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structures, **kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m other \u001b[38;5;129;01min\u001b[39;00m structures[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m    426\u001b[0m   assert_same_structure(structures[\u001b[38;5;241m0\u001b[39m], other, check_types\u001b[38;5;241m=\u001b[39mcheck_types)\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unflatten_as(structures[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m--> 428\u001b[0m                     [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(flatten, structures))])\n",
      "File \u001b[0;32m~/miniconda3/envs/tf312/lib/python3.12/site-packages/tensorflow_datasets/core/dataset_builder.py:1064\u001b[0m, in \u001b[0;36mDatasetBuilder._build_single_dataset\u001b[0;34m(self, split, batch_size, shuffle_files, decoders, read_config, as_supervised)\u001b[0m\n\u001b[1;32m   1061\u001b[0m   batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39msplits\u001b[38;5;241m.\u001b[39mtotal_num_examples \u001b[38;5;129;01mor\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmaxsize\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;66;03m# Build base dataset\u001b[39;00m\n\u001b[0;32m-> 1064\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_as_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mread_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;66;03m# Auto-cache small datasets which are small enough to fit in memory.\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_cache_ds(\n\u001b[1;32m   1073\u001b[0m     split\u001b[38;5;241m=\u001b[39msplit, shuffle_files\u001b[38;5;241m=\u001b[39mshuffle_files, read_config\u001b[38;5;241m=\u001b[39mread_config\n\u001b[1;32m   1074\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/tf312/lib/python3.12/site-packages/tensorflow_datasets/core/folder_dataset/image_folder.py:150\u001b[0m, in \u001b[0;36mImageFolder._as_dataset\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m read_config  \u001b[38;5;66;03m# Unused (automatically created in `DatasetBuilder`)\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m split \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39msplits\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    151\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized split \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. Subsplit API not yet supported for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    152\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSplit name should be one of \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    153\u001b[0m           split, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39msplits\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m    154\u001b[0m       )\n\u001b[1;32m    155\u001b[0m   )\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# Extract all labels/images\u001b[39;00m\n\u001b[1;32m    158\u001b[0m image_paths \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized split train. Subsplit API not yet supported for ImageFolder. Split name should be one of []."
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "builder = tfds.folder_dataset.ImageFolder('Dataset/Grayscale/Vehicles_Detection.v9i.tensorflow/')\n",
    "print(builder.info)\n",
    "raw_train = builder.as_dataset(split='train', shuffle_files=True)\n",
    "raw_test = builder.as_dataset(split='test', shuffle_files=True)\n",
    "raw_valid = builder.as_dataset(split='valid', shuffle_files=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
